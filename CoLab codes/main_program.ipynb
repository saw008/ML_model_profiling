{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brainstorm.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "w2-kqOdfU9Qh",
        "0uD_kzwR8N4V",
        "LwHmrYBS8Vo8",
        "b_y9ORzPHkj_",
        "jWFhmrKFAn29"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Test connection"
      ],
      "metadata": {
        "id": "w2-kqOdfU9Qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(client.list_database_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqyCgg3aU32j",
        "outputId": "fb6297d4-43cf-4825-ede4-522279a33a9c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thesis', 'admin', 'local']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### prep part"
      ],
      "metadata": {
        "id": "0uD_kzwR8N4V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkyXUr6U89Vy",
        "outputId": "7ae57eff-c8be-47c4-8b3c-3fb38eba5103"
      },
      "source": [
        "!pip3 install pymongo[srv]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pymongo[srv]) (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ-naRSa9C1O",
        "outputId": "82b38bcd-abcc-4210-bf6e-98a4083df2f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pymongo\n",
        "from bson.objectid import ObjectId\n",
        "import numpy as np\n",
        "\n",
        "# insert_one(), insert_many(), update_one(), update_many(), replace_one(), delete_one(), delete_many()\n",
        "# The following links are basic 101 to mongoDB x Python, in Chinese.\n",
        "# https://blog.csdn.net/culiu9261/article/details/107540063\n",
        "# https://www.runoob.com/python3/python-mongodb.html\n",
        "\n",
        "my_access_pwd = \"FNhkwCvGlAnRcntG\"\n",
        "my_url = \"mongodb+srv://saw008:\"+ my_access_pwd + \"@cluster0.9vbsx.mongodb.net/sampleTable?retryWrites=true&w=majority\"\n",
        "client = pymongo.MongoClient(my_url)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MeuRPe_9M9X",
        "outputId": "8cc24f2e-f2d5-4d57-f426-c37fe4f1568b"
      },
      "source": [
        "# Get all the databases in my cluster.\n",
        "print(client.list_database_names())\n",
        "table_data = client['thesis']['data_table']\n",
        "table_model = client['thesis']['model_table']\n",
        "table_perf = client['thesis']['performance_table123']"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thesis', 'admin', 'local']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJGTpqYw8ylO"
      },
      "source": [
        "def closest(test_query, num_of_entries = -1):\n",
        "    # All data and corresponding pattern\n",
        "    data_list = list(table_data.find({}, {\"pattern\": 1}))\n",
        "    if type(test_query) is dict:\n",
        "        # For stardard form of input dataset\n",
        "        # the pattern of input data\n",
        "        test_q_list = list(test_query['pattern'].values())\n",
        "    elif type(test_query) is list:\n",
        "        # For normal RAW dataset\n",
        "        test_q_list = [min(test_query), max(test_query), np.mean(test_query), np.std(test_query)]\n",
        "    tmp_dict = {}\n",
        "    for item in data_list:\n",
        "        tmp_lst = list(item['pattern'].values())\n",
        "        # Computing Euclidian Dist between test node to each node\n",
        "        current_dist = ((tmp_lst[0]-test_q_list[0])**2 + \\\n",
        "                        (tmp_lst[1]-test_q_list[1])**2 + \\\n",
        "                        (tmp_lst[2]-test_q_list[2])**2 + \\\n",
        "                        (tmp_lst[3]-test_q_list[3])**2) ** 0.5\n",
        "                        # (tmp_lst[3]-test_q_list[3])**2 + \\\n",
        "                        # (tmp_lst[4]-test_q_list[4])**2) ** 0.5\n",
        "        tmp_dict[item['_id']] = current_dist\n",
        "\n",
        "    # sorted tuple object, which is the ID and corresponding distance.\n",
        "    L = sorted(tmp_dict.items(), key=lambda item:item[1], reverse=False)\n",
        "\n",
        "    if num_of_entries > 0:\n",
        "        L = L[:num_of_entries]\n",
        "\n",
        "    # turn the list of tuples to a dict\n",
        "    dictdata = {}\n",
        "    for l in L:\n",
        "        dictdata[l[0]] = l[1]    \n",
        "    return dictdata\n",
        "\n",
        "def closest_helper(test_query, dataset_list, num_of_entries = -1):\n",
        "    data_list = []\n",
        "    for it in dataset_list:\n",
        "        data_list.append(table_data.find_one({'_id': ObjectId(it)}))\n",
        "    if type(test_query) is dict:\n",
        "        # For stardard form of input dataset\n",
        "        # the pattern of input data\n",
        "        test_q_list = list(test_query['pattern'].values())\n",
        "    elif type(test_query) is list:\n",
        "        # For normal RAW dataset\n",
        "        test_q_list = [min(test_query), max(test_query), np.mean(test_query), np.std(test_query)]\n",
        "    tmp_dict = {}\n",
        "    for item in data_list:\n",
        "        tmp_lst = list(item['pattern'].values())\n",
        "        # Computing Euclidian Dist between test node to each node\n",
        "        current_dist = ((tmp_lst[0]-test_q_list[0])**2 + \\\n",
        "                        (tmp_lst[1]-test_q_list[1])**2 + \\\n",
        "                        (tmp_lst[2]-test_q_list[2])**2 + \\\n",
        "                        (tmp_lst[3]-test_q_list[3])**2) ** 0.5\n",
        "\n",
        "        tmp_dict[item['_id']] = current_dist\n",
        "\n",
        "    # sorted tuple object, which is the ID and corresponding distance.\n",
        "    L = sorted(tmp_dict.items(), key=lambda item:item[1], reverse=False)\n",
        "\n",
        "    if num_of_entries > 0:\n",
        "        L = L[:num_of_entries]\n",
        "\n",
        "    # print(L)\n",
        "    \n",
        "    return L[0]\n",
        "\n",
        "\n",
        "def test_finder(test_query_data, expected_metric, N = -1):\n",
        "    try:\n",
        "        # <Step 1>: Get all the similar datasets.\n",
        "        closest_query_dataID_dist_dict = closest(test_query_data, 10)\n",
        "        # Top-N near datasets, in form of {dataID1:dist1, dataID2:dist2, ...}\n",
        "\n",
        "\n",
        "        # <Step 2>: Get all the models who used datasets as training dataset from step1.\n",
        "        query_id_trainData = list(table_model.find({}, {\"training_data\":  1}))\n",
        "        \n",
        "        # a dict of {modelID: [list_of_training_data]}\n",
        "        modelID_trainData_dict = {}\n",
        "        for item in query_id_trainData:\n",
        "            modelID_trainData_dict[list(item.values())[0]] = list(item.values())[1]\n",
        "        \n",
        "        tmp_matched_models = {}\n",
        "        for trainDataDict_of_one_model in modelID_trainData_dict:\n",
        "            tmp_set1 = set(closest_query_dataID_dist_dict.keys())\n",
        "            tmp_set2 = set(modelID_trainData_dict[trainDataDict_of_one_model])\n",
        "            tmp_intersection = tmp_set1.intersection(tmp_set2)\n",
        "            if len(tmp_intersection) != 0:\n",
        "                tmp_matched_models[trainDataDict_of_one_model] = len(tmp_intersection) # matched modelIDs\n",
        "                # All of the models who have similar-pattern datasets\n",
        "        # print(len(tmp_matched_models), tmp_matched_models)\n",
        "\n",
        "        # <Step 3>: Find all the test scenarios / performance who used models in step2.\n",
        "        matched_perf = []\n",
        "        tmp_metric = 'task.' + expected_metric\n",
        "        # print('*****')\n",
        "        for item in tmp_matched_models.keys():\n",
        "            matched_perfList_with_one_modelID = list(table_perf.find({'model_id': ObjectId(item)}, {'_id': 1, 'model_id': 1, 'test_data': 1, tmp_metric: 1}))\n",
        "            if len(matched_perfList_with_one_modelID) == 1:\n",
        "                # print('single')\n",
        "                tmp_perf_entry = table_perf.find_one({'model_id': ObjectId(item)}, {'_id': 0, 'model_id': 1, tmp_metric: 1})\n",
        "                tn = tmp_perf_entry\n",
        "                if tn is not None:\n",
        "                    print(tn)\n",
        "                    matched_perf.append(tn)\n",
        "            elif len(matched_perfList_with_one_modelID) > 1:\n",
        "                # print('multiple')\n",
        "                # For a model has multiple scenarios\n",
        "                aaa = {}\n",
        "                for it in matched_perfList_with_one_modelID:\n",
        "                    # print(it['test_data'])\n",
        "                    # aaa[it['test_data']] = it['model_id']\n",
        "                    aaa[it['test_data']] = it['_id']\n",
        "                    # print(table_data.find_one({'_id': ObjectId('5fbeb895e98c620967f2edac')}))\n",
        "                # print(matched_perfList_with_one_modelID)\n",
        "                # print(item)\n",
        "                closest_testData = closest_helper(test_query_data, aaa.keys())[0]\n",
        "                # closest_testData_corresponding_modelID = aaa[closest_testData]\n",
        "                closest_testData_corresponding_perfID = aaa[closest_testData]\n",
        "                # tn = closest_testData_corresponding_modelID\n",
        "                tn = closest_testData_corresponding_perfID\n",
        "                if tn is not None:\n",
        "                    # print(tn)\n",
        "                    matched_perf.append(table_perf.find_one({'_id': ObjectId(tn)}, {'_id': 0, 'model_id': 1, tmp_metric: 1}))\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        # print('*****')\n",
        "        new_s = sorted(matched_perf, key = lambda e:e.__getitem__('task').__getitem__(expected_metric))\n",
        "        if N != -1:\n",
        "            new_s = new_s[:N]\n",
        "\n",
        "        return new_s # in set/dict format\n",
        "    except ValueError:\n",
        "        print('Invalid list, please check again')\n",
        "        return None"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Algo"
      ],
      "metadata": {
        "id": "LwHmrYBS8Vo8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsiJ5UWkAzzN",
        "outputId": "1d9ddcb0-4fff-40f3-e5ec-dd8405e5a9a7"
      },
      "source": [
        "full_data_table = list(table_data.find({}))\n",
        "\n",
        "tmp_perf_entry = table_perf.find({}, {'test_data': 1, '_id': 0})\n",
        "tmp_list = list(tmp_perf_entry)\n",
        "distinct_test_data = set()\n",
        "for item in tmp_list:\n",
        "    distinct_test_data.add(item['test_data'])\n",
        "tmp_distinct = list(distinct_test_data)\n",
        "\n",
        "# print(len(tmp_distinct))\n",
        "\n",
        "\n",
        "search = table_data.find_one({'_id': tmp_distinct[1]})\n",
        "print(search)\n",
        "\n",
        "# print(search)\n",
        "print(f\"Let's search: {search['pattern']}\")\n",
        "# print(closest(search, -1))\n",
        "results = test_finder(search, '500-RMSE', 5)\n",
        "print(len(results), results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "{'_id': ObjectId('5fbeb895e98c620967f2ed56'), 'pattern': {'min': 59.9974, 'max': 60.0133, 'avg': 60.0032, 'std': 0.001, 'no_of_samples': 1375}, 'measurement': 'frequency', 'data_path': '/content/drive/My Drive/myThesis/test001/Training/scenario104'}\n",
            "Let's search: {'min': 59.9974, 'max': 60.0133, 'avg': 60.0032, 'std': 0.001, 'no_of_samples': 1375}\n",
            "7 {ObjectId('5fc5267ef9ad7c82692b9a88'): 1, ObjectId('5fc526cff9ad7c82692b9a8d'): 1, ObjectId('5fc526cff9ad7c82692b9aa3'): 1, ObjectId('5fc5267ef9ad7c82692b9a81'): 2, ObjectId('5fc526cff9ad7c82692b9a8c'): 1, ObjectId('5fc526cff9ad7c82692b9aa1'): 1, ObjectId('5fc5267ef9ad7c82692b9a89'): 1}\n",
            "*****\n",
            "multiple\n",
            "61afc91cb2235aac34cc2ad2\n",
            "multiple\n",
            "61afc962b2235aac34cc2ae9\n",
            "multiple\n",
            "61afc962b2235aac34cc2b14\n",
            "multiple\n",
            "61afc91cb2235aac34cc2aab\n",
            "multiple\n",
            "61afc962b2235aac34cc2ae7\n",
            "multiple\n",
            "61afc91cb2235aac34cc2ad8\n",
            "*****\n",
            "5 [{'model_id': ObjectId('5fc5267ef9ad7c82692b9a89'), 'task': {'500-RMSE': 0.00054591}}, {'model_id': ObjectId('5fc526cff9ad7c82692b9aa3'), 'task': {'500-RMSE': 0.00129537}}, {'model_id': ObjectId('5fc5267ef9ad7c82692b9a88'), 'task': {'500-RMSE': 0.00234515}}, {'model_id': ObjectId('5fc526cff9ad7c82692b9a8c'), 'task': {'500-RMSE': 0.00311936}}, {'model_id': ObjectId('5fc5267ef9ad7c82692b9a81'), 'task': {'500-RMSE': 0.00316254}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing"
      ],
      "metadata": {
        "id": "XnGySexzAtUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test prep function"
      ],
      "metadata": {
        "id": "b_y9ORzPHkj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(test_query_data, expected_metric, N = -1):\n",
        "    try:\n",
        "        # <Step 1>: Get all the similar datasets.\n",
        "        closest_query_dataID_dist_dict = closest(test_query_data, 10)\n",
        "        # Top-N near datasets, in form of {dataID1:dist1, dataID2:dist2, ...}\n",
        "\n",
        "\n",
        "        # <Step 2>: Get all the models who used datasets as training dataset from step1.\n",
        "        query_id_trainData = list(table_model.find({}, {\"training_data\":  1}))\n",
        "        \n",
        "        # a dict of {modelID: [list_of_training_data]}\n",
        "        modelID_trainData_dict = {}\n",
        "        for item in query_id_trainData:\n",
        "            modelID_trainData_dict[list(item.values())[0]] = list(item.values())[1]\n",
        "        \n",
        "        tmp_matched_models = {}\n",
        "        for trainDataDict_of_one_model in modelID_trainData_dict:\n",
        "            tmp_set1 = set(closest_query_dataID_dist_dict.keys())\n",
        "            tmp_set2 = set(modelID_trainData_dict[trainDataDict_of_one_model])\n",
        "            tmp_intersection = tmp_set1.intersection(tmp_set2)\n",
        "            if len(tmp_intersection) != 0:\n",
        "                tmp_matched_models[trainDataDict_of_one_model] = len(tmp_intersection) # matched modelIDs\n",
        "                # All of the models who have similar-pattern datasets\n",
        "        # print(len(tmp_matched_models), tmp_matched_models)\n",
        "\n",
        "        # <Step 3>: Find all the test scenarios / performance who used models in step2.\n",
        "        matched_perf = []\n",
        "        tmp_metric = 'task.' + expected_metric\n",
        "        # print('*****')\n",
        "        for item in tmp_matched_models.keys():\n",
        "            matched_perfList_with_one_modelID = list(temp_col.find({'model_id': ObjectId(item)}, {'_id': 1, 'model_id': 1, 'test_data': 1, tmp_metric: 1}))\n",
        "            if len(matched_perfList_with_one_modelID) == 1:\n",
        "                # print('single')\n",
        "                tmp_perf_entry = temp_col.find_one({'model_id': ObjectId(item)}, {'_id': 0, 'model_id': 1, tmp_metric: 1})\n",
        "                tn = tmp_perf_entry\n",
        "                if tn is not None:\n",
        "                    print(tn)\n",
        "                    matched_perf.append(tn)\n",
        "            elif len(matched_perfList_with_one_modelID) > 1:\n",
        "                # print('multiple')\n",
        "                # For a model has multiple scenarios\n",
        "                aaa = {}\n",
        "                for it in matched_perfList_with_one_modelID:\n",
        "                    # print(it['test_data'])\n",
        "                    # aaa[it['test_data']] = it['model_id']\n",
        "                    aaa[it['test_data']] = it['_id']\n",
        "                    # print(table_data.find_one({'_id': ObjectId('5fbeb895e98c620967f2edac')}))\n",
        "                # print(matched_perfList_with_one_modelID)\n",
        "                # print(item)\n",
        "                closest_testData = closest_helper(test_query_data, aaa.keys())[0]\n",
        "                # closest_testData_corresponding_modelID = aaa[closest_testData]\n",
        "                closest_testData_corresponding_perfID = aaa[closest_testData]\n",
        "                # tn = closest_testData_corresponding_modelID\n",
        "                tn = closest_testData_corresponding_perfID\n",
        "                if tn is not None:\n",
        "                    # print(tn)\n",
        "                    matched_perf.append(temp_col.find_one({'_id': ObjectId(tn)}, {'_id': 0, 'model_id': 1, tmp_metric: 1}))\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        # print('*****')\n",
        "        new_s = sorted(matched_perf, key = lambda e:e.__getitem__('task').__getitem__(expected_metric))\n",
        "        if N != -1:\n",
        "            new_s = new_s[:N]\n",
        "\n",
        "        return new_s # in set/dict format\n",
        "    except ValueError:\n",
        "        print('Invalid list, please check again')\n",
        "        return None\n",
        "\n",
        "def test_case(dataNo, k, metric):\n",
        "    client['thesis']['temp'].drop()\n",
        "    ground_truth = []\n",
        "    number = dataNo\n",
        "\n",
        "    tmp_perf_entry = table_perf.find({}, {'test_data': 1, '_id': 0})\n",
        "    tmp_list = list(tmp_perf_entry)\n",
        "    distinct_test_data = set()\n",
        "    for item in tmp_list:\n",
        "        distinct_test_data.add(item['test_data'])\n",
        "    tmp_distinct = list(distinct_test_data)\n",
        "    search = table_data.find_one({'_id': tmp_distinct[number]})\n",
        "\n",
        "    results = test_finder(search, metric)\n",
        "    for _ in results:\n",
        "        ground_truth.append(str(_['model_id']))\n",
        "    # print(ground_truth)\n",
        "    # print(len(ground_truth))\n",
        "\n",
        "    precision_at_k = 0\n",
        "    recall_at_k = 0\n",
        "    d = search['_id']\n",
        "    print('d ->', d)\n",
        "\n",
        "    my_db = client['thesis']\n",
        "    my_db.create_collection('temp')\n",
        "    my_db.list_collection_names()\n",
        "    mmm = table_perf.find()\n",
        "    temp_col = my_db['temp']\n",
        "    temp_col.insert_many(mmm)\n",
        "    count_before = len(list(temp_col.find()))\n",
        "    temp_list = list(temp_col.find({'test_data': ObjectId(d)}, {'_id': 1}))\n",
        "    for item in temp_list:\n",
        "        temp_col.delete_one({'_id': item['_id']})\n",
        "    count_after = len(list(temp_col.find()))\n",
        "    # print(f'Deleted {count_before-count_after} records.')\n",
        "\n",
        "    # print(f\"Let's search: {search['pattern']}\")\n",
        "    # print(closest(search, -1))\n",
        "    results2 = testing(search, metric, k)\n",
        "    # print(len(results2), results2)\n",
        "\n",
        "    found = []\n",
        "    for _ in results2:\n",
        "        found.append(str(_['model_id']))\n",
        "    # print(ground_truth)\n",
        "    # print(found)\n",
        "    # print(len(found))\n",
        "    # print()\n",
        "    # print(list(results))\n",
        "    # print(list(results2))\n",
        "    # print(set(ground_truth).intersection(set(found)))\n",
        "    precision_at_k = len(set(ground_truth).intersection(set(found))) / k\n",
        "    recall_at_k = len(set(ground_truth).intersection(set(found))) / len(ground_truth)\n",
        "    print(f\"Precision @ {k} is: {precision_at_k}\")\n",
        "    print(f\"Recall @ {k} is: {recall_at_k}\")\n",
        "    print('****************')\n",
        "    print()\n",
        "\n",
        "def test_case2(dataNo, k, metric):\n",
        "    client['thesis']['temp'].drop()\n",
        "    ground_truth = []\n",
        "    number = dataNo\n",
        "    top_what = k\n",
        "\n",
        "    tmp_perf_entry = table_perf.find({}, {'test_data': 1, '_id': 0})\n",
        "    tmp_list = list(tmp_perf_entry)\n",
        "    distinct_test_data = set()\n",
        "    for item in tmp_list:\n",
        "        distinct_test_data.add(item['test_data'])\n",
        "    tmp_distinct = list(distinct_test_data)\n",
        "    search = table_data.find_one({'_id': tmp_distinct[number]})\n",
        "\n",
        "    results = test_finder(search, metric, top_what)\n",
        "    for _ in results:\n",
        "        ground_truth.append(str(_['model_id']))\n",
        "    # print(ground_truth)\n",
        "    # print(len(ground_truth))\n",
        "\n",
        "    precision_at_k = 0\n",
        "    recall_at_k = 0\n",
        "    d = search['_id']\n",
        "    print('d ->', d)\n",
        "\n",
        "    my_db = client['thesis']\n",
        "    my_db.create_collection('temp')\n",
        "    my_db.list_collection_names()\n",
        "    mmm = table_perf.find()\n",
        "    temp_col = my_db['temp']\n",
        "    temp_col.insert_many(mmm)\n",
        "    count_before = len(list(temp_col.find()))\n",
        "    temp_list = list(temp_col.find({'test_data': ObjectId(d)}, {'_id': 1}))\n",
        "    for item in temp_list:\n",
        "        temp_col.delete_one({'_id': item['_id']})\n",
        "    count_after = len(list(temp_col.find()))\n",
        "    # print(f'Deleted {count_before-count_after} records.')\n",
        "\n",
        "    print(f\"Let's search: {search['pattern']}\")\n",
        "    # print(closest(search, -1))\n",
        "    results2 = testing(search, metric, top_what)\n",
        "    # print(len(results2), results2)\n",
        "\n",
        "    found = []\n",
        "    for _ in results2:\n",
        "        found.append(str(_['model_id']))\n",
        "    abs_gap = []\n",
        "    for i in range(len(results)):\n",
        "        ratio = results2[i]['task'][metric] / results[i]['task'][metric]\n",
        "        abs_gap.append(abs(1-ratio))\n",
        "    # print(ground_truth)\n",
        "    # print(found)\n",
        "    # print(len(found))\n",
        "    print()\n",
        "    if len(found) >= 3:\n",
        "        precision_at_3 = len(set(ground_truth[:3]).intersection(set(found[:3]))) / 3\n",
        "        recall_at_3 = len(set(ground_truth[:3]).intersection(set(found[:3]))) / len(ground_truth)\n",
        "        print('---------------------------------')\n",
        "        print(f\"Precision @ 3 is: {round(precision_at_3, 2)}\")\n",
        "        print(f\"Recall @ 3 is: {round(recall_at_3, 2)}\")\n",
        "        print(f\"Absolute pref gap @ 3 is: {round(np.mean(abs_gap[:3]), 2)}\")\n",
        "    if len(found) >= 5:\n",
        "        precision_at_5 = len(set(ground_truth[:5]).intersection(set(found[:5]))) / 5\n",
        "        recall_at_5 = len(set(ground_truth[:5]).intersection(set(found[:5]))) / len(ground_truth)\n",
        "        print('---------------------------------')\n",
        "        print(f\"Precision @ 5 is: {round(precision_at_5, 2)}\")\n",
        "        print(f\"Recall @ 5 is: {round(recall_at_5, 2)}\")\n",
        "        print(f\"Absolute pref gap @ 5 is: {round(np.mean(abs_gap[:5]), 2)}\")\n",
        "    if len(found) >= 7:\n",
        "        precision_at_7 = len(set(ground_truth[:7]).intersection(set(found[:7]))) / 7\n",
        "        recall_at_7 = len(set(ground_truth[:7]).intersection(set(found[:7]))) / len(ground_truth)\n",
        "        print('---------------------------------')\n",
        "        print(f\"Precision @ 7 is: {round(precision_at_7, 2)}\")\n",
        "        print(f\"Recall @ 7 is: {round(recall_at_7, 2)}\")\n",
        "        print(f\"Absolute pref gap @ 7 is: {round(np.mean(abs_gap[:7]), 2)}\")\n",
        "\n",
        "    print('*****************************************************')\n",
        "    print()\n",
        "    # print(results)\n",
        "    # print(results2)"
      ],
      "metadata": {
        "id": "cW98WnCzfozI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### test 1"
      ],
      "metadata": {
        "id": "OqBuWzeuHYUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_case2(19, 3, '500-MAE')\n",
        "test_case2(3, 5, 'Inference_Time')\n",
        "test_case2(55, 7, '500-RMSE')\n",
        "test_case2(48, 9, 'Training_Time')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iIrJytdfdB6",
        "outputId": "fbba100e-f227-4564-9c5f-9c7bf194134e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d -> 5fbeb895e98c620967f2ed75\n",
            "Let's search: {'min': 59.9977, 'max': 60.0272, 'avg': 60.007, 'std': 0.0034, 'no_of_samples': 1375}\n",
            "\n",
            "---------------------------------\n",
            "Precision @ 3 is: 0.67\n",
            "Recall @ 3 is: 0.67\n",
            "Absolute pref gap @ 3 is: 0.01\n",
            "*****************************************************\n",
            "\n",
            "d -> 5fbeb895e98c620967f2ee1f\n",
            "Let's search: {'min': 59.9968, 'max': 60.0006, 'avg': 59.9998, 'std': 0.0004, 'no_of_samples': 1375}\n",
            "\n",
            "---------------------------------\n",
            "Precision @ 3 is: 1.0\n",
            "Recall @ 3 is: 0.6\n",
            "Absolute pref gap @ 3 is: 0.0\n",
            "---------------------------------\n",
            "Precision @ 5 is: 1.0\n",
            "Recall @ 5 is: 1.0\n",
            "Absolute pref gap @ 5 is: 0.0\n",
            "*****************************************************\n",
            "\n",
            "d -> 5fbeb895e98c620967f2ee84\n",
            "Let's search: {'min': 59.9964, 'max': 60.0153, 'avg': 60.0017, 'std': 0.0017, 'no_of_samples': 1375}\n",
            "\n",
            "---------------------------------\n",
            "Precision @ 3 is: 0.67\n",
            "Recall @ 3 is: 0.29\n",
            "Absolute pref gap @ 3 is: 0.07\n",
            "---------------------------------\n",
            "Precision @ 5 is: 1.0\n",
            "Recall @ 5 is: 0.71\n",
            "Absolute pref gap @ 5 is: 0.06\n",
            "---------------------------------\n",
            "Precision @ 7 is: 1.0\n",
            "Recall @ 7 is: 1.0\n",
            "Absolute pref gap @ 7 is: 0.04\n",
            "*****************************************************\n",
            "\n",
            "d -> 5fbeb895e98c620967f2ed1f\n",
            "Let's search: {'min': 59.9944, 'max': 60.0181, 'avg': 60.0026, 'std': 0.0015, 'no_of_samples': 1375}\n",
            "\n",
            "---------------------------------\n",
            "Precision @ 3 is: 1.0\n",
            "Recall @ 3 is: 0.38\n",
            "Absolute pref gap @ 3 is: 0.0\n",
            "---------------------------------\n",
            "Precision @ 5 is: 1.0\n",
            "Recall @ 5 is: 0.62\n",
            "Absolute pref gap @ 5 is: 0.0\n",
            "---------------------------------\n",
            "Precision @ 7 is: 1.0\n",
            "Recall @ 7 is: 0.88\n",
            "Absolute pref gap @ 7 is: 0.0\n",
            "*****************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*others*"
      ],
      "metadata": {
        "id": "jWFhmrKFAn29"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4ECwoA69gYH",
        "outputId": "bdb93c2b-3c19-4dcf-bb7f-d999b5162d37"
      },
      "source": [
        "from bson.objectid import ObjectId\n",
        "item = '5fc526cff9ad7c82692b9a8d'\n",
        "tmp_metric = 'task.' + 'Inference_Time'\n",
        "tmp_perf_entry = table_perf.find_one({'task.task_category': \"prediction\"})\n",
        "# print(tmp_perf_entry)\n",
        "tmp_perf_entry = table_perf.find({}, {'test_data': 1, '_id': 0})\n",
        "tmp_list = list(tmp_perf_entry)\n",
        "print(tmp_list)\n",
        "\n",
        "distinct_test_data = set()\n",
        "for item in tmp_list:\n",
        "    distinct_test_data.add(item['test_data'])\n",
        "tmp_distinct = list(distinct_test_data)\n",
        "print(len(tmp_distinct), tmp_distinct)\n",
        "# print(ObjectId('5fbeb895e98c620967f2ee56') in tmp_distinct)\n",
        "# print(list(table_perf.find()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'test_data': ObjectId('5fbeb895e98c620967f2ed03')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed11')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed1e')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed9f')}, {'test_data': ObjectId('5fbeb895e98c620967f2edd8')}, {'test_data': ObjectId('5fbeb895e98c620967f2edf5')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee04')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee74')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed1f')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed2d')}, {'test_data': ObjectId('5fbeb895e98c620967f2ede6')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee1f')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee57')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee66')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee84')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee91')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed48')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed91')}, {'test_data': ObjectId('5fbeb895e98c620967f2edac')}, {'test_data': ObjectId('5fbeb895e98c620967f2edad')}, {'test_data': ObjectId('5fbeb895e98c620967f2edba')}, {'test_data': ObjectId('5fbeb895e98c620967f2edf6')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee20')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee03')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee65')}, {'test_data': ObjectId('5fbeb895e98c620967f2eea0')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed57')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed74')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed83')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed84')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee11')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee3a')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee75')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed3b')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee56')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed02')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed56')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed92')}, {'test_data': ObjectId('5fbeb895e98c620967f2edd7')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee2c')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee2d')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee3b')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee83')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee93')}, {'test_data': ObjectId('5fbeb895e98c620967f2eea2')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed2e')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed3a')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed47')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed65')}, {'test_data': ObjectId('5fbeb895e98c620967f2ede7')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee47')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed10')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed66')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed75')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed9e')}, {'test_data': ObjectId('5fbeb895e98c620967f2edbb')}, {'test_data': ObjectId('5fbeb895e98c620967f2edc8')}, {'test_data': ObjectId('5fbeb895e98c620967f2edc9')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee12')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee48')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed10')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed2e')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed47')}, {'test_data': ObjectId('5fbeb895e98c620967f2edc8')}, {'test_data': ObjectId('5fbeb895e98c620967f2ede6')}, {'test_data': ObjectId('5fbeb895e98c620967f2edf6')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee2d')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee03')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee56')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed2d')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed9e')}, {'test_data': ObjectId('5fbeb895e98c620967f2edba')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee04')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee3a')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee65')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee91')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee93')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed03')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed3a')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed11')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed74')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed84')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee20')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee75')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee83')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed1f')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed3b')}, {'test_data': ObjectId('5fbeb895e98c620967f2edad')}, {'test_data': ObjectId('5fbeb895e98c620967f2edbb')}, {'test_data': ObjectId('5fbeb895e98c620967f2edc9')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee3b')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee48')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed02')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed48')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed92')}, {'test_data': ObjectId('5fbeb895e98c620967f2edac')}, {'test_data': ObjectId('5fbeb895e98c620967f2edd8')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee12')}, {'test_data': ObjectId('5fbeb895e98c620967f2eea0')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed57')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed65')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed66')}, {'test_data': ObjectId('5fbeb895e98c620967f2edd7')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee47')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee84')}, {'test_data': ObjectId('5fbeb895e98c620967f2eea2')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed75')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed83')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee1f')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee2c')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee57')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee66')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee74')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed1e')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed56')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed91')}, {'test_data': ObjectId('5fbeb895e98c620967f2ed9f')}, {'test_data': ObjectId('5fbeb895e98c620967f2ede7')}, {'test_data': ObjectId('5fbeb895e98c620967f2ee11')}, {'test_data': ObjectId('5fbeb895e98c620967f2edf5')}]\n",
            "60 [ObjectId('5fbeb895e98c620967f2ee3a'), ObjectId('5fbeb895e98c620967f2ee91'), ObjectId('5fbeb895e98c620967f2ede6'), ObjectId('5fbeb895e98c620967f2edba'), ObjectId('5fbeb895e98c620967f2ed3a'), ObjectId('5fbeb895e98c620967f2ed2d'), ObjectId('5fbeb895e98c620967f2ee03'), ObjectId('5fbeb895e98c620967f2ede7'), ObjectId('5fbeb895e98c620967f2ed03'), ObjectId('5fbeb895e98c620967f2ed57'), ObjectId('5fbeb895e98c620967f2ee84'), ObjectId('5fbeb895e98c620967f2eea0'), ObjectId('5fbeb895e98c620967f2ee2c'), ObjectId('5fbeb895e98c620967f2ed83'), ObjectId('5fbeb895e98c620967f2ed1e'), ObjectId('5fbeb895e98c620967f2ee93'), ObjectId('5fbeb895e98c620967f2edbb'), ObjectId('5fbeb895e98c620967f2ee56'), ObjectId('5fbeb895e98c620967f2ee65'), ObjectId('5fbeb895e98c620967f2ed10'), ObjectId('5fbeb895e98c620967f2ee48'), ObjectId('5fbeb895e98c620967f2ee3b'), ObjectId('5fbeb895e98c620967f2ed9e'), ObjectId('5fbeb895e98c620967f2ee83'), ObjectId('5fbeb895e98c620967f2ed66'), ObjectId('5fbeb895e98c620967f2ee12'), ObjectId('5fbeb895e98c620967f2ee11'), ObjectId('5fbeb895e98c620967f2edd8'), ObjectId('5fbeb895e98c620967f2ed92'), ObjectId('5fbeb895e98c620967f2ee75'), ObjectId('5fbeb895e98c620967f2ee2d'), ObjectId('5fbeb895e98c620967f2ee66'), ObjectId('5fbeb895e98c620967f2ed84'), ObjectId('5fbeb895e98c620967f2ed47'), ObjectId('5fbeb895e98c620967f2edc9'), ObjectId('5fbeb895e98c620967f2ee04'), ObjectId('5fbeb895e98c620967f2edf5'), ObjectId('5fbeb895e98c620967f2ed75'), ObjectId('5fbeb895e98c620967f2ed74'), ObjectId('5fbeb895e98c620967f2ee57'), ObjectId('5fbeb895e98c620967f2ed91'), ObjectId('5fbeb895e98c620967f2ed1f'), ObjectId('5fbeb895e98c620967f2ed2e'), ObjectId('5fbeb895e98c620967f2ed65'), ObjectId('5fbeb895e98c620967f2ed9f'), ObjectId('5fbeb895e98c620967f2eea2'), ObjectId('5fbeb895e98c620967f2ed48'), ObjectId('5fbeb895e98c620967f2edac'), ObjectId('5fbeb895e98c620967f2ed02'), ObjectId('5fbeb895e98c620967f2edd7'), ObjectId('5fbeb895e98c620967f2ee47'), ObjectId('5fbeb895e98c620967f2edc8'), ObjectId('5fbeb895e98c620967f2edf6'), ObjectId('5fbeb895e98c620967f2ed3b'), ObjectId('5fbeb895e98c620967f2ed56'), ObjectId('5fbeb895e98c620967f2ee74'), ObjectId('5fbeb895e98c620967f2ee20'), ObjectId('5fbeb895e98c620967f2edad'), ObjectId('5fbeb895e98c620967f2ed11'), ObjectId('5fbeb895e98c620967f2ee1f')]\n",
            "{'test_data': ObjectId('5fbeb895e98c620967f2ed03')}\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client['thesis']['temp'].drop()\n",
        "ground_truth = []\n",
        "number = 9\n",
        "k = 7\n",
        "metric = '500-MAE'\n",
        "top_what = 7\n",
        "\n",
        "tmp_perf_entry = table_perf.find({}, {'test_data': 1, '_id': 0})\n",
        "tmp_list = list(tmp_perf_entry)\n",
        "distinct_test_data = set()\n",
        "for item in tmp_list:\n",
        "    distinct_test_data.add(item['test_data'])\n",
        "tmp_distinct = list(distinct_test_data)\n",
        "search = table_data.find_one({'_id': tmp_distinct[number]})\n",
        "\n",
        "results = test_finder(search, metric, top_what)\n",
        "for _ in results:\n",
        "    ground_truth.append(str(_['model_id']))\n",
        "# print(ground_truth)\n",
        "# print(len(ground_truth))\n",
        "\n",
        "precision_at_k = 0\n",
        "recall_at_k = 0\n",
        "d = search['_id']\n",
        "print('d ->', d)\n",
        "\n",
        "my_db = client['thesis']\n",
        "my_db.create_collection('temp')\n",
        "my_db.list_collection_names()\n",
        "mmm = table_perf.find()\n",
        "temp_col = my_db['temp']\n",
        "temp_col.insert_many(mmm)\n",
        "count_before = len(list(temp_col.find()))\n",
        "temp_list = list(temp_col.find({'test_data': ObjectId(d)}, {'_id': 1}))\n",
        "for item in temp_list:\n",
        "    temp_col.delete_one({'_id': item['_id']})\n",
        "count_after = len(list(temp_col.find()))\n",
        "# print(f'Deleted {count_before-count_after} records.')\n",
        "\n",
        "print(f\"Let's search: {search['pattern']}\")\n",
        "# print(closest(search, -1))\n",
        "results2 = testing(search, metric, top_what)\n",
        "# print(len(results2), results2)\n",
        "\n",
        "found = []\n",
        "for _ in results2:\n",
        "    found.append(str(_['model_id']))\n",
        "abs_gap = []\n",
        "for i in range(len(results)):\n",
        "    ratio = results2[i]['task'][metric] / results[i]['task'][metric]\n",
        "    abs_gap.append(abs(1-ratio))\n",
        "# print(ground_truth)\n",
        "# print(found)\n",
        "# print(len(found))\n",
        "print()\n",
        "if len(found) >= 3:\n",
        "    precision_at_3 = len(set(ground_truth[:3]).intersection(set(found[:3]))) / 3\n",
        "    recall_at_3 = len(set(ground_truth[:3]).intersection(set(found[:3]))) / len(ground_truth)\n",
        "    print('---------------------------------')\n",
        "    print(f\"Precision @ 3 is: {round(precision_at_3, 2)}\")\n",
        "    print(f\"Recall @ 3 is: {round(recall_at_3, 2)}\")\n",
        "    print(f\"Absolute pref gap @ 3 is: {round(np.mean(abs_gap[:3]), 2)}\")\n",
        "if len(found) >= 5:\n",
        "    precision_at_5 = len(set(ground_truth[:5]).intersection(set(found[:5]))) / 5\n",
        "    recall_at_5 = len(set(ground_truth[:5]).intersection(set(found[:5]))) / len(ground_truth)\n",
        "    print('---------------------------------')\n",
        "    print(f\"Precision @ 5 is: {round(precision_at_5, 2)}\")\n",
        "    print(f\"Recall @ 5 is: {round(recall_at_5, 2)}\")\n",
        "    print(f\"Absolute pref gap @ 5 is: {round(np.mean(abs_gap[:5]), 2)}\")\n",
        "if len(found) >= 7:\n",
        "    precision_at_7 = len(set(ground_truth[:7]).intersection(set(found[:7]))) / 7\n",
        "    recall_at_7 = len(set(ground_truth[:7]).intersection(set(found[:7]))) / len(ground_truth)\n",
        "    print('---------------------------------')\n",
        "    print(f\"Precision @ 7 is: {round(precision_at_7, 2)}\")\n",
        "    print(f\"Recall @ 7 is: {round(recall_at_7, 2)}\")\n",
        "    print(f\"Absolute pref gap @ 7 is: {round(np.mean(abs_gap[:7]), 2)}\")\n",
        "\n",
        "print()\n",
        "# print(results)\n",
        "# print(results2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSyuTl9Axdj",
        "outputId": "39eaafd4-c87a-435a-a3de-c1cd0bc883a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d -> 5fbeb895e98c620967f2ee12\n",
            "Let's search: {'min': 59.9949, 'max': 60.0018, 'avg': 60.0, 'std': 0.0003, 'no_of_samples': 1375}\n",
            "\n",
            "---------------------------------\n",
            "Precision @ 3 is: 0.67\n",
            "Recall @ 3 is: 0.29\n",
            "Absolute pref gap @ 3 is: 0.23\n",
            "---------------------------------\n",
            "Precision @ 5 is: 1.0\n",
            "Recall @ 5 is: 0.71\n",
            "Absolute pref gap @ 5 is: 0.28\n",
            "---------------------------------\n",
            "Precision @ 7 is: 1.0\n",
            "Recall @ 7 is: 1.0\n",
            "Absolute pref gap @ 7 is: 0.2\n",
            "\n"
          ]
        }
      ]
    }
  ]
}